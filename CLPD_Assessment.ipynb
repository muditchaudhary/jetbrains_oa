{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JetBrains ML Engineer Intern (CLPD) Test  Assignment\n",
    "\n",
    "__Task Description:__\n",
    "Please, send us a link to a git repository with the self-contained, reproducible Jupyter notebook that includes code and text comparing any two existing open source solutions for the problem described in the position posting (e.g enry and pygments) on some small but realistic dataset of your choice (e.g clone several OSS git repositories). It must be possible to re-run all the cells in the notebook without any errors to get similar results. Be prepared to discuss the implementation details and trade-offs of each of the chosen approaches.  \n",
    "\n",
    "__Job posting link:__ https://www.jetbrains.com/careers/jobs/ml-engineer-intern-cpld-705/  \n",
    "\n",
    "__Candidate Name:__ Mudit Chaudhary  \n",
    "__Candidate Email:__ mchaudhary@umass.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chosen Open source solutions programming language detection task\n",
    "\n",
    "In this assignment, I choose the following open source solutions for the programming language detection task:\n",
    "\n",
    "1. __Enry:__ Programming language detector and toolbox to ignore binary or vendored files. enry, started as a port to Go of the original Linguist Ruby library, that has an improved 2x performance. [Link](https://github.com/go-enry/go-enry)\n",
    "\n",
    "2. __GuessLang:__ Guesslang is neural network based programming language detector which supports over 50 programming languages. It is also used by Microsoft VS Code for programming languages detection. [Link](https://guesslang.readthedocs.io/en/latest/)\n",
    "\n",
    "### 1.1 Motivation to choose these solutions\n",
    "These two solutions are chosen because of their inherent differences in how they approach the problem. Enry focuses on a multi-faceted approach by utilizing not only the file content but also other features such as file name, extensions, etc., whereas, Guesslang only focuses on the file content. We will discuss about the differences between their implementations as we go through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Requirements to run this notebook\n",
    "\n",
    "The Jupyter notebook assumes the following programming languages are already installed on the system:\n",
    "1. Python (Tested on 3.7 or later)\n",
    "2. Go (Tested on 1.17.3)\n",
    "\n",
    "Most of the requirements are installed within this notebook. However, if due to JetBrain's organization constraints you cannot install the packages from within the Jupyter notebook, the required packages are listed below:\n",
    "\n",
    "\n",
    "1. guesslang == 2.2.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following coding cell installs the required packages. Please do not run if the packages are installed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting guesslang\n",
      "  Using cached guesslang-2.2.1-py3-none-any.whl (2.5 MB)\n",
      "Collecting tensorflow==2.5.0\n",
      "  Downloading tensorflow-2.5.0-cp37-cp37m-macosx_10_11_x86_64.whl (195.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 195.6 MB 72 kB/s  eta 0:00:01     |████████████████████████████▌   | 174.4 MB 1.4 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from tensorflow==2.5.0->guesslang) (0.37.0)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp37-cp37m-macosx_10_10_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.5\n",
      "  Using cached tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp37-cp37m-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 604 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
      "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Using cached numpy-1.19.5-cp37-cp37m-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp37-cp37m-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 739 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from tensorflow==2.5.0->guesslang) (1.15.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow==2.5.0->guesslang) (58.0.4)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->guesslang) (2.0.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 465 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 348 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0->guesslang) (2020.6.20)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mudit/miniconda3/envs/testJBOA/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0->guesslang) (3.3.1)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=9c613a1e5c0ecef1e42f82a06a417721a24286b5b0314c40a1ad213c553e2a48\n",
      "  Stored in directory: /Users/mudit/Library/Caches/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-macosx_10_9_x86_64.whl size=32572 sha256=6a391070d5341b0570aa38ef7ec9d93c260fb125164d49c8ae34b7294033fcd3\n",
      "  Stored in directory: /Users/mudit/Library/Caches/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, cached-property, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow, guesslang\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 charset-normalizer-2.0.7 flatbuffers-1.12 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 guesslang-2.2.1 h5py-3.1.0 idna-3.3 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 urllib3-1.26.7 werkzeug-2.0.2 wrapt-1.12.1\n",
      "go mod init: go.mod already exists\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install guesslang\n",
    "!go mod init jetbrain_oa.com/enryExample\n",
    "!go get github.com/go-enry/go-enry/v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset \n",
    "The dataset that I'll evaluate and compare the two solutions is collected from open source github repositories. The small dataset consists of the following repositories:\n",
    "\n",
    "1. [facebook/DPR](https://github.com/facebookresearch/DPR)\n",
    "2. [Homebrew/brew](https://github.com/Homebrew/brew)\n",
    "3. [newrelic/opensource-website](https://github.com/newrelic/opensource-website)\n",
    "4. [kkos/oniguruma](https://github.com/kkos/oniguruma)\n",
    "5. [Azure/azure-storage-net-data-movement](https://github.com/Azure/azure-storage-net-data-movement)\n",
    "6. [laravel/laravel](https://github.com/laravel/laravel)\n",
    "\n",
    "This collection of repositories is deliberately chosen so as to increase the language diversity and repository structure. The data is available in the ```data``` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statement\n",
    "import time\n",
    "import guesslang\n",
    "from typing import List, Tuple, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------  \n",
    "----------------------------------------------------------------------------------------------  \n",
    "## 4. Comparison \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparison of language detection features\n",
    "\n",
    "In this section, we compare the difference in major language detection features that aforementioned solutions offer. After describing the differences, we go on to show implementation of those features through code. We do not compare the list of languages offered by these two solutions in this section.\n",
    "\n",
    "![alt text](./images/feature_comparison.png)\n",
    "\n",
    "From a quick observation, we might conclude that Guesslang doesn't hold anywhere near Enry. However, we need to understand that these two solutions are at very different stages of development and for a slightly different idealogy. Enry offers a full repository analysis, whereas GuessLang focuses on programming language detection on coding snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Using Guesslang on a single code file\n",
    "\n",
    "We pick a single code file ```./data/DPR/generate_dense_embeddings.py``` which is a python code. We will also check the time it takes for GuessLang to process the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessLangFile(filepath: str, verbose=False, topk=3, model=None) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Given a file path, return the source code probabilities \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    if model == None:\n",
    "        guessLangModel = guesslang.Guess()\n",
    "    else:\n",
    "        guessLangModel = model\n",
    "    endModelInit = time.time()\n",
    "    codeFile = open(filepath, \"r\")\n",
    "    code = codeFile.read()\n",
    "    codeFile.close()\n",
    "    probs = guessLangModel.probabilities(code)\n",
    "    \n",
    "    end = time.time()   \n",
    "    if verbose:\n",
    "        file_size = os.path.getsize(filepath)\n",
    "        if model == None:\n",
    "            print(\"Time to intialize guessLang model(secs) \" + str(endModelInit-start))\n",
    "        print(\"Total time to execute(secs) \" + str(end-start))        \n",
    "        \n",
    "        \n",
    "    return probs[:topk] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilties and time taken to execute with model initialized inside the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to intialize guessLang model(secs) 0.7328689098358154\n",
      "Total time to execute(secs) 0.9116120338439941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Python', 1.0),\n",
       " ('Julia', 1.2100569435347097e-09),\n",
       " ('Lua', 3.5541371928848875e-11)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guessLangFile(\"./data/DPR/generate_dense_embeddings.py\", verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilties and time taken to execute with model initialized outside the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to execute(secs) 0.13572311401367188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Python', 1.0),\n",
       " ('Julia', 1.2100569435347097e-09),\n",
       " ('Lua', 3.5541371928848875e-11)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = guesslang.Guess()\n",
    "guessLangFile(\"./data/DPR/generate_dense_embeddings.py\", verbose = True, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Using Enry on a single code file\n",
    "\n",
    "We pick a single code file ```./data/DPR/generate_dense_embeddings.py``` which is a python code. We will also check the time it takes for enry to process. \n",
    "As enry does not provide reliable python bindings, we use Golang code in the file ```./code/enry_singleFile.go```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  ./data/DPR/generate_dense_embeddings.py\r\n",
      "Predicted language:  Python\r\n",
      "2021/11/13 09:57:37 Total execution time(secs)  0.000187\r\n"
     ]
    }
   ],
   "source": [
    "!go run code/enry_singleFile.go ./data/DPR/generate_dense_embeddings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Using Enry and Guesslang on files with different sizes\n",
    "We will run enry and Guesslang on the following files with different sizes.\n",
    "\n",
    "1. ```./data/azure-storage-net-data-movement/lib/NativeMD5.cs (8776 bytes) (C#)```\n",
    "2. ```./data/brew/Library/Homebrew/utils.rb (15079 bytes) (Ruby)```\n",
    "3. ```./data/brew/Library/Homebrew/tap_constants.rb (959 bytes) (Ruby)```\n",
    "4. ```./data/opensource-website/jest-preprocess.js (169 bytes) (Javascript)```\n",
    "5. ```./data/DPR/dpr/models/pytext_models.py (4915 bytes) (Python)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ./data/brew/Library/Homebrew/utils.rb\n",
      "Total time to execute(secs) 0.012228250503540039\n",
      "[('Ruby', 1.0)]\n",
      "Filename: ./data/azure-storage-net-data-movement/lib/NativeMD5.cs\n",
      "Total time to execute(secs) 0.005077838897705078\n",
      "[('C#', 0.9999887943267822)]\n",
      "Filename: ./data/brew/Library/Homebrew/tap_constants.rb\n",
      "Total time to execute(secs) 0.0031890869140625\n",
      "[('Shell', 0.3526136875152588)]\n",
      "Filename: ./data/opensource-website/jest-preprocess.js\n",
      "Total time to execute(secs) 0.0038750171661376953\n",
      "[('JavaScript', 0.3400322496891022)]\n",
      "Filename: ./data/DPR/dpr/models/pytext_models.py\n",
      "Total time to execute(secs) 0.003789186477661133\n",
      "[('Python', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "files = [ \"./data/brew/Library/Homebrew/utils.rb\",\"./data/azure-storage-net-data-movement/lib/NativeMD5.cs\",\n",
    "        \"./data/brew/Library/Homebrew/tap_constants.rb\", \"./data/opensource-website/jest-preprocess.js\", \"./data/DPR/dpr/models/pytext_models.py\"]\n",
    "\n",
    "for file in files:\n",
    "    print(\"Filename: \"+ file)\n",
    "    print(guessLangFile(file, verbose = True, model=model, topk=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  ./data/azure-storage-net-data-movement/lib/NativeMD5.cs\n",
      "Predicted language:  C#\n",
      "2021/11/13 09:57:46 Total execution time(secs)  0.000182\n",
      "Filename:  ./data/brew/Library/Homebrew/utils.rb\n",
      "Predicted language:  Ruby\n",
      "2021/11/13 09:57:47 Total execution time(secs)  0.000148\n",
      "Filename:  ./data/brew/Library/Homebrew/tap_constants.rb\n",
      "Predicted language:  Ruby\n",
      "2021/11/13 09:57:48 Total execution time(secs)  0.000182\n",
      "Filename:  ./data/opensource-website/jest-preprocess.js\n",
      "Predicted language:  JavaScript\n",
      "2021/11/13 09:57:49 Total execution time(secs)  0.000144\n",
      "Filename:  ./data/DPR/dpr/models/pytext_models.py\n",
      "Predicted language:  Python\n",
      "2021/11/13 09:57:50 Total execution time(secs)  0.000165\n"
     ]
    }
   ],
   "source": [
    "!go run code/enry_singleFile.go ./data/azure-storage-net-data-movement/lib/NativeMD5.cs\n",
    "\n",
    "!go run code/enry_singleFile.go ./data/brew/Library/Homebrew/utils.rb\n",
    "\n",
    "!go run code/enry_singleFile.go ./data/brew/Library/Homebrew/tap_constants.rb \n",
    "\n",
    "!go run code/enry_singleFile.go ./data/opensource-website/jest-preprocess.js\n",
    "\n",
    "!go run code/enry_singleFile.go ./data/DPR/dpr/models/pytext_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Observations\n",
    "\n",
    "In this section, I present my observations from running the above mini-experiment. I also present a graph showing the time it took for these solution on different file sizes (ran on CPU system not GPU).\n",
    "\n",
    "![alt text](./images/executionTimeComparison.png)\n",
    "\n",
    "We can make the following observations:\n",
    "1. GuessLang's execution time has a higher positive correlation to the file size in comparison to enry. This due to the fact that GuessLang only uses fole content for prediction whereas enry uses other strategies as described above.\n",
    "2. GuessLang has an associated warmup time on the first time execution i.e., once the model is loaded, the execution time reduces in comparison for the next run due to model available in the cache.\n",
    "3. GuessLang gets 1 prediction wrong for ```./data/brew/Library/Homebrew/tap_constants.rb```. It predicts ```Shell``` instead of ```Ruby```\n",
    "4. Enry has faster execution time in comparison to GuessLang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Comparison of filtering features\n",
    "\n",
    "Enry offers filtering features to have an option ignore files such as binaries, configuration, documentation, etc.\n",
    "GuessLang does not provide such filtering options.\n",
    "\n",
    "Enry provides the following filters:\n",
    "1. IsBinary\n",
    "2. IsVendor\n",
    "3. IsConfiguration\n",
    "4. IsDocumentation\n",
    "5. IsDotFile\n",
    "6. IsImage\n",
    "7. IsTest\n",
    "8. IsGenerated\n",
    "\n",
    "These filters are useful when running an automated code repository analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Present filtering features \n",
    "In this section, we show how some of enry's filtering features work. \n",
    "We will perform these functions on the following files:\n",
    "\n",
    "1. ```./data/DPR/conf/extractive_reader_train_cfg.yaml (Configuration file)```\n",
    "2. ```./data/opensource-website/README.md (Documentation file)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  ./data/DPR/conf/extractive_reader_train_cfg.yaml\r\n",
      "Is Config?  true\r\n",
      "Is Documentation?  false\r\n",
      "2021/11/13 09:58:17 Total execution time(secs)  0.000087\r\n"
     ]
    }
   ],
   "source": [
    "!go run ./code/enry_filter.go ./data/DPR/conf/extractive_reader_train_cfg.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:  ./data/opensource-website/README.md\r\n",
      "Is Config?  false\r\n",
      "Is Documentation?  true\r\n",
      "2021/11/13 09:58:19 Total execution time(secs)  0.000075\r\n"
     ]
    }
   ],
   "source": [
    "!go run ./code/enry_filter.go ./data/opensource-website/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Command line tools\n",
    "\n",
    "Both enry and Guesslang provide command line tools. However, the command line tools for GuessLang are limited in comparison. GuessLang can only run the analysis on a single file, whereas enry can run a full-fledged code analysis of a repo without additional coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Present Command line tools for enry\n",
    "\n",
    "In this section, we will run enry's command line tool on all the repos in our dataset for code analysis. There were some issues in installing enry CLI. I am instead running their CLI code instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.52%\tRuby\n",
      "2.29%\tfish\n",
      "1.90%\tShell\n",
      "1.71%\tRoff Manpage\n",
      "0.50%\tHTML+ERB\n",
      "0.03%\tSwift\n",
      "0.03%\tDockerfile\n",
      "0.01%\tPostScript\n",
      "Time to execute 1 enry command over 1 repo(secs) 1.7724599838256836\n"
     ]
    }
   ],
   "source": [
    "# On Repo Brew\n",
    "start = time.time()\n",
    "!(cd ./data/brew && go run ../../enry/main.go)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time to execute 1 enry command over 1 repo(secs) \" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.80%\tC#\r\n",
      "0.14%\tBatchfile\r\n",
      "0.05%\tPowerShell\r\n"
     ]
    }
   ],
   "source": [
    "# On Repo azure-storage-net-data-movement\n",
    "!(cd ./data/azure-storage-net-data-movement && go run ../../enry/main.go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.71%\tPHP\r\n",
      "17.73%\tBlade\r\n",
      "0.56%\tJavaScript\r\n",
      "0.00%\tCSS\r\n"
     ]
    }
   ],
   "source": [
    "# On Repo laravel\n",
    "!(cd ./data/laravel && go run ../../enry/main.go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.29%\tC\r\n",
      "2.42%\tShell\r\n",
      "1.85%\tPython\r\n",
      "0.65%\tHTML\r\n",
      "0.38%\tCMake\r\n",
      "0.24%\tMakefile\r\n",
      "0.10%\tM4Sugar\r\n",
      "0.05%\tC++\r\n",
      "0.02%\tBatchfile\r\n"
     ]
    }
   ],
   "source": [
    "# On Repo oniguruma\n",
    "!(cd ./data/oniguruma && go run ../../enry/main.go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.16%\tJavaScript\r\n",
      "14.34%\tSCSS\r\n",
      "0.49%\tCSS\r\n"
     ]
    }
   ],
   "source": [
    "# On Repo opensource-website\n",
    "!(cd ./data/opensource-website && go run ../../enry/main.go)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Present Command line tools for GuessLang\n",
    "\n",
    "GuessLang CLI cannot perform repository analysis like enry. It can be used to perform programming language identification per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programming language: Python\n",
      "Programming language: Ruby\n",
      "Programming language: Shell\n",
      "Time to execute 3 GuessLang CLI commands(secs) 11.259923934936523\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "!guesslang ./data/DPR/generate_dense_embeddings.py\n",
    "!guesslang ./data/brew/Library/Homebrew/brew.rb\n",
    "!guesslang ./data/brew/Library/Homebrew/tap_constants.rb\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time to execute 3 GuessLang CLI commands(secs) \" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 Observations\n",
    "\n",
    "We can observe the following from enry and GuessLang tools:\n",
    "1. GuessLang CLI tool's functionality is fairly limited in comparison to enry.\n",
    "2. Enry's CLI tool is much faster in comparison. This might be because GuessLang's CLI tool requires model loading everytime the command call is made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Difference between content-based classifiers\n",
    "\n",
    "Enry uses a Naive Bayesian Classifier for its content-based classifier, whereas GuessLang uses a Linear Neural Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that enry's performance in terms of speed surpasses GuessLang. Although enry uses a simpler classifier model but because of additional strategies such as using filename extension, shebang, model line, etc. it is able to perform well. However, its performance might be affected if only the code-snippet is available. Enry provides more functionality such as filteringa and repository code analysis.\n",
    "\n",
    "GuessLang is a simpler solution which only provides content-based classification using a neural network. Because it was developed to be used in situations where only the code-snippets are available, it performs well under those conditions. It is reported to have 93.45% accuracy over a test dataset of 230,000 source code files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
